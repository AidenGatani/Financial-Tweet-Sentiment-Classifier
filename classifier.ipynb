{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "691770dc-9388-4727-a3ed-7dfa9e795290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc48c1-5ec7-4abf-8659-25cd3c477103",
   "metadata": {},
   "source": [
    "# Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05854a4c-a053-4d90-bf64-8faecbe7681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"zeroshot/twitter-financial-news-topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d875e4bd-8cd5-4166-8efb-ee654350bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "label_mapping = {\n",
    "    0: \"Analyst Update\",\n",
    "    1: \"Fed | Central Banks\",\n",
    "    2: \"Company | Product News\",\n",
    "    3: \"Treasuries | Corporate Debt\",\n",
    "    4: \"Dividend\",\n",
    "    5: \"Earnings\",\n",
    "    6: \"Energy | Oil\",\n",
    "    7: \"Financials\",\n",
    "    8: \"Currencies\",\n",
    "    9: \"General News | Opinion\",\n",
    "    10: \"Gold | Metals | Materials\",\n",
    "    11: \"IPO\",\n",
    "    12: \"Legal | Regulation\",\n",
    "    13: \"M&A | Investments\",\n",
    "    14: \"Macro\",\n",
    "    15: \"Markets\",\n",
    "    16: \"Politics\",\n",
    "    17: \"Personnel Change\",\n",
    "    18: \"Stock Commentary\",\n",
    "    19: \"Stock Movement\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5baa6e-64a0-4cf1-9255-d4cf50cb4db2",
   "metadata": {},
   "source": [
    "## Exploring The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2969cd-04c6-42eb-98d8-cb7a644409ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16990\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ca0d5-a70b-467f-a56c-ed7ceb797c6f",
   "metadata": {},
   "source": [
    "# Loading The Model And Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "657a3aed-4d7b-4b5d-b252-dd8822b215f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5929aa33-cfa3-496c-aaab-222baad74726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13426b2b1adb4048a1a2e3e9418dbf9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize The Data\n",
    "tokenized_datasets = {}\n",
    "\n",
    "for split in dataset.keys():\n",
    "    tokenized_datasets[split] = dataset[split].map(lambda x: tokenizer(x['text'], truncation=True, padding=\"max_length\"), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f5b82c-f89d-455a-88d5-ce1cd42d210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 16990\n",
       " }),\n",
       " 'validation': Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 4117\n",
       " })}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2009ab25-376d-4509-95a5-e4359e8cdfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load The Model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=20,\n",
    "                                 id2label=label_mapping)\n",
    "\n",
    "# freeze Model Parameters\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef8a50-1fb0-413f-a991-a55492c2e543",
   "metadata": {},
   "source": [
    "## Exploring The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3891a0-2666-46ad-91fc-d0ebf351f221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b69c210-859a-4da7-a9a2-ae48ee4ded3c",
   "metadata": {},
   "source": [
    "# PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae3e9bf0-a87d-4f46-ba4d-85995d110438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e66fc3e9-53b6-4248-98cb-b0304bfdd75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 05:14:44.149677: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-18 05:14:44.193455: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fb90387-0400-4760-ab7b-a189327239ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd5446eb-8f19-49b7-a641-26df3d323f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "\n",
    "def training(model, tokenizer, datasets, compute_metrics):\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./data',\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=5,\n",
    "        load_best_model_at_end=True,\n",
    "        learning_rate=2e-5,\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch')\n",
    "    \n",
    "    return Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datasets[\"train\"],\n",
    "        eval_dataset=datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b545f09-9ad0-4c48-89f9-b6795997f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lora Config File\n",
    "config = LoraConfig(r=10, target_modules=['q_lin', 'k_lin', 'v_lin', 'lin1', 'lin2'], \n",
    "                    lora_alpha=16, lora_dropout=0.1, bias=\"none\", \n",
    "                    task_type=TaskType.SEQ_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5f66fb6-20ab-4f98-be8d-7899910a3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model With PEFT Config File\n",
    "lora_model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a797d9e6-0644-438d-af9a-c3c45f0360ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,343,252 || all params: 68,312,104 || trainable%: 1.9663455249453303\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8cc483-359f-49b3-b5ac-f1301274997f",
   "metadata": {},
   "source": [
    "## Evaluate Model Prior To FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2ae4261-6297-45c6-9416-a3e794f14ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = training(model, tokenizer, tokenized_datasets, compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b09d7a9-f531-4157-8e25-bd22d10efa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1809fd4f-8ed4-43a2-982a-663fb70bc19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.050250768661499,\n",
       " 'eval_accuracy': 0.004615010930289046,\n",
       " 'eval_runtime': 31.0012,\n",
       " 'eval_samples_per_second': 132.801,\n",
       " 'eval_steps_per_second': 8.322}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ba0b26d-42c5-43e3-9d33-e286b41fe200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyst call of the day for @CNBCPro subscribe...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loop upgrades CSX to buy, says it's a good pla...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BofA believes we're already in a recession — a...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPMorgan sees these derivative plays as best w...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morgan Stanley's Huberty sees Apple earnings m...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>LISTEN NOW: Netflix reported that it lost fewe...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ford's Mustang Mach-E electric crossover is a ...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Coinbase says it has no exposure to collapsed ...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GM reveals electric Chevrolet Blazer priced st...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nikola adjourns shareholder meeting, again, as...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label  predicted_label\n",
       "0   Analyst call of the day for @CNBCPro subscribe...      0               10\n",
       "1   Loop upgrades CSX to buy, says it's a good pla...      0               10\n",
       "2   BofA believes we're already in a recession — a...      0               10\n",
       "3   JPMorgan sees these derivative plays as best w...      0               10\n",
       "4   Morgan Stanley's Huberty sees Apple earnings m...      0               10\n",
       "..                                                ...    ...              ...\n",
       "95  LISTEN NOW: Netflix reported that it lost fewe...      2               10\n",
       "96  Ford's Mustang Mach-E electric crossover is a ...      2               10\n",
       "97  Coinbase says it has no exposure to collapsed ...      2               10\n",
       "98  GM reveals electric Chevrolet Blazer priced st...      2               10\n",
       "99  Nikola adjourns shareholder meeting, again, as...      2               10\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tokenized_datasets[\"validation\"])\n",
    "df = df[[\"text\", \"label\"]]\n",
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa14a3-d407-4f7c-a058-ab2ea5e60938",
   "metadata": {},
   "source": [
    "## Train PEFT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22925028-d70a-4f22-9904-4b507962d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_trainer = training(lora_model, tokenizer, tokenized_datasets, compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d958a3-365f-4ae8-bea5-706f03d901de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5310' max='5310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5310/5310 29:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.468200</td>\n",
       "      <td>1.174579</td>\n",
       "      <td>0.660189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.952900</td>\n",
       "      <td>0.820407</td>\n",
       "      <td>0.761234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.764500</td>\n",
       "      <td>0.696440</td>\n",
       "      <td>0.786252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.684700</td>\n",
       "      <td>0.648547</td>\n",
       "      <td>0.798640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.663300</td>\n",
       "      <td>0.632180</td>\n",
       "      <td>0.802526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./data/checkpoint-1062 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/checkpoint-2124 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/checkpoint-3186 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5310, training_loss=0.9933307683625014, metrics={'train_runtime': 1754.9362, 'train_samples_per_second': 48.406, 'train_steps_per_second': 3.026, 'total_flos': 1.16072614514688e+16, 'train_loss': 0.9933307683625014, 'epoch': 5.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f5f39b4-8aec-411c-8fda-fca8211afeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60ef4574-6eba-406c-8e2a-b7ce94b33eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEFT Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2f1f99b-3c9a-40bb-9957-f1b97f799a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 00:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6321803331375122,\n",
       " 'eval_accuracy': 0.802526111246053,\n",
       " 'eval_runtime': 32.3303,\n",
       " 'eval_samples_per_second': 127.342,\n",
       " 'eval_steps_per_second': 7.98}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2a2dd50-a8ed-408c-b88c-6ef33ff6f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyst call of the day for @CNBCPro subscribe...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loop upgrades CSX to buy, says it's a good pla...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BofA believes we're already in a recession — a...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPMorgan sees these derivative plays as best w...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morgan Stanley's Huberty sees Apple earnings m...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>LISTEN NOW: Netflix reported that it lost fewe...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ford's Mustang Mach-E electric crossover is a ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Coinbase says it has no exposure to collapsed ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GM reveals electric Chevrolet Blazer priced st...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nikola adjourns shareholder meeting, again, as...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label  predicted_label\n",
       "0   Analyst call of the day for @CNBCPro subscribe...      0                5\n",
       "1   Loop upgrades CSX to buy, says it's a good pla...      0                2\n",
       "2   BofA believes we're already in a recession — a...      0               15\n",
       "3   JPMorgan sees these derivative plays as best w...      0                2\n",
       "4   Morgan Stanley's Huberty sees Apple earnings m...      0                5\n",
       "..                                                ...    ...              ...\n",
       "95  LISTEN NOW: Netflix reported that it lost fewe...      2                2\n",
       "96  Ford's Mustang Mach-E electric crossover is a ...      2                2\n",
       "97  Coinbase says it has no exposure to collapsed ...      2                2\n",
       "98  GM reveals electric Chevrolet Blazer priced st...      2                2\n",
       "99  Nikola adjourns shareholder meeting, again, as...      2               17\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tokenized_datasets[\"validation\"])\n",
    "df = df[[\"text\", \"label\"]]\n",
    "predictions = peft_trainer.predict(tokenized_datasets[\"validation\"])\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc828445-2432-4a28-81dd-f32eb7376bf0",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fd08b0b-09fa-4b6b-9c02-17aa2c3b68aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification\n",
    "\n",
    "inference_model = AutoPeftModelForSequenceClassification.from_pretrained(\"lora_model\",  num_labels=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bf4964a-12d7-4c46-9186-56c76d5e546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet1 = 'The 10 bitcoin ETFs netted +$2.3b last week. For context, that is more than any other ETF (out of 3,400) took in. $IBIT alone was #2. This brings total net to +$5b, which is more than BlackRock as a whole has taken in. Again, this is all net GBTC bleed. Throw that out and the numbers get even crazier.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "957668c4-d480-4482-ac5d-c1eaf430f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet2 = 'We have released a Research Discussion Paper - \\'Do Monetary Policy and Economic Conditions Impact Innovation? Evidence from Australian Administrative Data\\' - https://t.ly/OVa5E'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a187b42-3872-46c9-98dc-3d066b915549",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet3 = 'At its meeting today, the Board decided to leave the cash rate target unchanged at 4.35 per cent and the interest rate paid on Exchange Settlement balances unchanged at 4.25 per cent.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ee980dd-8dcc-42de-8639-fe0ef1d91684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inf(text):\n",
    "    input = tokenizer(text, \n",
    "                  padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    logits = inference_model(**input).logits\n",
    "    predictions = torch.argmax(logits,dim=1).numpy()[0]\n",
    "\n",
    "    print(f'Tweet: {text}')\n",
    "    print()\n",
    "    print(f'Prediction: {predictions} ({label_mapping[predictions]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0eae36e3-c040-4415-89ad-14ab44dcb5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: The 10 bitcoin ETFs netted +$2.3b last week. For context, that is more than any other ETF (out of 3,400) took in. $IBIT alone was #2. This brings total net to +$5b, which is more than BlackRock as a whole has taken in. Again, this is all net GBTC bleed. Throw that out and the numbers get even crazier.\n",
      "\n",
      "Prediction: 18 (Stock Commentary)\n"
     ]
    }
   ],
   "source": [
    "run_inf(tweet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14e8d68a-b0c8-4dda-a631-ed5fd0f3c178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: We have released a Research Discussion Paper - 'Do Monetary Policy and Economic Conditions Impact Innovation? Evidence from Australian Administrative Data' - https://t.ly/OVa5E\n",
      "\n",
      "Prediction: 14 (Macro)\n"
     ]
    }
   ],
   "source": [
    "run_inf(tweet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7ee28cd-9409-440b-ad47-88462581b1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: At its meeting today, the Board decided to leave the cash rate target unchanged at 4.35 per cent and the interest rate paid on Exchange Settlement balances unchanged at 4.25 per cent.\n",
      "\n",
      "Prediction: 1 (Fed | Central Banks)\n"
     ]
    }
   ],
   "source": [
    "run_inf(tweet3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb8dd2-b7fc-4c3f-856d-9416fc3cb034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
